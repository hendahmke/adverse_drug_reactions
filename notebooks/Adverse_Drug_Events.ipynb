{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adverse Drug Events.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFhAZdtkYrNO"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGWhRE5BdKLP",
        "outputId": "0a12ccc0-bd6d-4357-b21a-bc436c6cb98c"
      },
      "source": [
        "import pandas as pd # DataFrame Manipulation Package\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # Convert a collection of raw documents to a matrix of TF-IDF features\n",
        "from sklearn.decomposition import LatentDirichletAllocation # Latent Dirichlet Allocation is a topic model that is used for discovering abstract topics from a collection of documents (variational Bayes algorithm)\n",
        "from sklearn.feature_extraction.text import CountVectorizer # Convert a collection of text documents to a matrix of token counts\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB # The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification)\n",
        "\n",
        "import string # Collection of string operations\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.wordnet import WordNetLemmatizer #Lemmatize using WordNet's built-in morphy function. Returns the input word unchanged if it cannot be found in WordNet.\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from nltk.sentiment.util import mark_negation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtTAm1pM4S1J",
        "outputId": "79d64528-8059-4006-fce5-0493989b84c8"
      },
      "source": [
        "!pip install corextopic"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: corextopic in /usr/local/lib/python3.6/dist-packages (1.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwlPZL0Nve81",
        "outputId": "2bfc31fa-c641-4cc9-c5c3-3aec5b98b5c8"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laSyLC8bYzfb"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj-5L5mXHEcw"
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "for negation in [\"no\", \"not\", \"shouldn't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"wasn't\", \"weren't\", \"wouldn't\"]:\n",
        "    stop_words.remove(negation)\n",
        "\n",
        "#stop_words"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-NO8IZarxx7"
      },
      "source": [
        "def to_list(x):\n",
        "    list_words = x.split(' ')\n",
        "    return list_words\n",
        "\n",
        "def to_string(x):\n",
        "    string = \" \".join(x)\n",
        "    return string\n",
        "\n",
        "#===============================================================\n",
        "\n",
        "def punctuation(x):\n",
        "    for punctuation in string.punctuation:\n",
        "        x =  x.replace(punctuation, '')\n",
        "    return x.lower()\n",
        "\n",
        "def remove_numbers (x):\n",
        "    words_only = ''.join([i for i in x if not i.isdigit()])\n",
        "    return words_only\n",
        "\n",
        "def m_negation(x):\n",
        "    tokenized = word_tokenize(x)\n",
        "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
        "    tokenized_neg = mark_negation(without_stopwords)\n",
        "    return tokenized_neg\n",
        "\n",
        "def remove_stopwords(x):\n",
        "    tokenized = word_tokenize(x)\n",
        "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
        "    return without_stopwords\n",
        "\n",
        "def lemmatize_review(x):\n",
        "    lemma = WordNetLemmatizer()\n",
        "    lista = []\n",
        "    for w in x:\n",
        "       lista.append(lemma.lemmatize(w))\n",
        "    return lista\n",
        "\n",
        "#===============================================================\n",
        "\n",
        "def count_words(x):\n",
        "    wordfreq = []\n",
        "    for w in x:\n",
        "        wordfreq.append(x.count(w))\n",
        "    return dict(zip(x, wordfreq))\n",
        "\n",
        "def total_count(x):\n",
        "    total_count = {}\n",
        "    for row in x:\n",
        "        for key in row.keys():\n",
        "          if key in total_count:\n",
        "              total_count[key] += 1\n",
        "          else:\n",
        "              total_count[key] = 1\n",
        "    return pd.DataFrame(sorted(total_count.items(), key=lambda x: x[1], reverse=True)).head(30).T\n",
        "\n",
        "#===============================================================\n",
        "\n",
        "def print_topics(model, vectorizer):\n",
        "    for idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic %d:\" % (idx))\n",
        "        print([(vectorizer.get_feature_names()[i], round(topic[i], 2))\n",
        "                        for i in topic.argsort()[:-10 - 1:-1]])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBXYxVWOMNB7"
      },
      "source": [
        "# Manual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "rGlZiURk-Bj-",
        "outputId": "9e0f20a7-f92d-4979-a66a-02e240710ac1"
      },
      "source": [
        "manual = pd.read_csv('manually_labelled_data.csv')\n",
        "\n",
        "manual = manual.drop([\"uniqueID\", \"drugName\", \"condition\", \"date\", \"rating\", \"usefulCount\"], axis = 1)\n",
        "\n",
        "manual[\"clean_review\"] = manual[\"review\"].apply(punctuation)\n",
        "manual['clean_review'] = manual.clean_review.apply(remove_numbers)\n",
        "manual['clean_review_lst'] = manual.clean_review.apply(to_list)\n",
        "\n",
        "manual[\"NonStopwords_review_lst\"] = manual.clean_review.apply(remove_stopwords)\n",
        "manual[\"NonStopwords_review_str\"] = manual.NonStopwords_review_lst.apply(to_string)\n",
        "\n",
        "manual[\"NonStopwords_review_lst_MN\"] = manual.clean_review.apply(m_negation)\n",
        "manual[\"NonStopwords_review_str_MN\"] = manual.NonStopwords_review_lst_MN.apply(to_string)\n",
        "\n",
        "manual[\"Lemmatized_review_lst\"] = manual.NonStopwords_review_lst_MN.apply(lemmatize_review)\n",
        "manual[\"Lemmatized_review_str\"] = manual.Lemmatized_review_lst.apply(to_string)\n",
        "\n",
        "manual[\"Lemmatized_review\"] = manual.NonStopwords_review_lst.apply(lemmatize_review)\n",
        "manual[\"Lemmatized_review\"] = manual.Lemmatized_review.apply(to_string)\n",
        "\n",
        "manual[\"words_count\"] = manual.Lemmatized_review_lst.apply(count_words)\n",
        "\n",
        "X = manual[\"Lemmatized_review_str\"]\n",
        "\n",
        "y = manual[\"sideEffect\"]\n",
        "\n",
        "manual.head(3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sideEffect</th>\n",
              "      <th>clean_review</th>\n",
              "      <th>clean_review_lst</th>\n",
              "      <th>NonStopwords_review_lst</th>\n",
              "      <th>NonStopwords_review_str</th>\n",
              "      <th>NonStopwords_review_lst_MN</th>\n",
              "      <th>NonStopwords_review_str_MN</th>\n",
              "      <th>Lemmatized_review_lst</th>\n",
              "      <th>Lemmatized_review_str</th>\n",
              "      <th>Lemmatized_review</th>\n",
              "      <th>words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>0</td>\n",
              "      <td>it has no side effect i take it in combination...</td>\n",
              "      <td>[it, has, no, side, effect, i, take, it, in, c...</td>\n",
              "      <td>[no, side, effect, take, combination, bystolic...</td>\n",
              "      <td>no side effect take combination bystolic mg fi...</td>\n",
              "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
              "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
              "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
              "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
              "      <td>no side effect take combination bystolic mg fi...</td>\n",
              "      <td>{'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>my son is halfway through his fourth week of i...</td>\n",
              "      <td>[my, son, is, halfway, through, his, fourth, w...</td>\n",
              "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
              "      <td>son halfway fourth week intuniv became concern...</td>\n",
              "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
              "      <td>son halfway fourth week intuniv became concern...</td>\n",
              "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
              "      <td>son halfway fourth week intuniv became concern...</td>\n",
              "      <td>son halfway fourth week intuniv became concern...</td>\n",
              "      <td>{'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>i used to take another oral contraceptive whic...</td>\n",
              "      <td>[i, used, to, take, another, oral, contracepti...</td>\n",
              "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
              "      <td>used take another oral contraceptive pill cycl...</td>\n",
              "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
              "      <td>used take another oral contraceptive pill cycl...</td>\n",
              "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
              "      <td>used take another oral contraceptive pill cycl...</td>\n",
              "      <td>used take another oral contraceptive pill cycl...</td>\n",
              "      <td>{'used': 1, 'take': 1, 'another': 1, 'oral': 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                        words_count\n",
              "0  \"It has no side effect, I take it in combinati...  ...  {'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...\n",
              "1  \"My son is halfway through his fourth week of ...  ...  {'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...\n",
              "2  \"I used to take another oral contraceptive, wh...  ...  {'used': 1, 'take': 1, 'another': 1, 'oral': 1...\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGPQ7uu9F219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c6fe87-23f1-42c3-9571-fc707b9ea807"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7On82pfF664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7f21ec-fe0f-48b7-8d54-7a28b3583f9c"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx3n6MXR2Kw5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "76dff28b-a2ed-46aa-d045-567ab4d4bf1b"
      },
      "source": [
        "total_count(manual[\"words_count\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>day</td>\n",
              "      <td>side_NEG</td>\n",
              "      <td>not_NEG</td>\n",
              "      <td>not</td>\n",
              "      <td>year</td>\n",
              "      <td>effects_NEG</td>\n",
              "      <td>taking</td>\n",
              "      <td>started</td>\n",
              "      <td>mg</td>\n",
              "      <td>no</td>\n",
              "      <td>week</td>\n",
              "      <td>im</td>\n",
              "      <td>take_NEG</td>\n",
              "      <td>month</td>\n",
              "      <td>first</td>\n",
              "      <td>like_NEG</td>\n",
              "      <td>time</td>\n",
              "      <td>took</td>\n",
              "      <td>one</td>\n",
              "      <td>would_NEG</td>\n",
              "      <td>started_NEG</td>\n",
              "      <td>day_NEG</td>\n",
              "      <td>taking_NEG</td>\n",
              "      <td>pain</td>\n",
              "      <td>ive</td>\n",
              "      <td>take</td>\n",
              "      <td>time_NEG</td>\n",
              "      <td>work_NEG</td>\n",
              "      <td>ago</td>\n",
              "      <td>two</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0         1        2    3     4   ...    25        26        27   28   29\n",
              "0  day  side_NEG  not_NEG  not  year  ...  take  time_NEG  work_NEG  ago  two\n",
              "1   28        26       24   24    24  ...    12        12        12   12   11\n",
              "\n",
              "[2 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGs0FYOJYuiw"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXE8dbR5deD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1d06f1-37d3-48d6-c944-c9971b133ced"
      },
      "source": [
        "data = pd.read_csv('drugsComTrain_raw.csv')\n",
        "\n",
        "print(f\"The shape of the data is {data.shape[0]} rows and {data.shape[1]} columns\")\n",
        "print(\"\\n\")\n",
        "print(f\"The amount of unique ID is {len(data['uniqueID'].unique())}\") # check if any of the uniqueID repeat\n",
        "print(\"\\n\")\n",
        "print(f\"The number of unique drugs reviewed is {len(data['drugName'].unique())}\")\n",
        "print(\"\\n\")\n",
        "print(f\"The number of unique conditions is {len(data['condition'].unique())}\")\n",
        "print(\"\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the data is 161297 rows and 7 columns\n",
            "\n",
            "\n",
            "The amount of unique ID is 161297\n",
            "\n",
            "\n",
            "The number of unique drugs reviewed is 3436\n",
            "\n",
            "\n",
            "The number of unique conditions is 885\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNZe0N5PjZyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "719a93e1-a4ab-4f98-c7ad-c2401a70cb86"
      },
      "source": [
        "pd.DataFrame(data[\"drugName\"].value_counts()).head(14).T"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Levonorgestrel</th>\n",
              "      <th>Etonogestrel</th>\n",
              "      <th>Ethinyl estradiol / norethindrone</th>\n",
              "      <th>Nexplanon</th>\n",
              "      <th>Ethinyl estradiol / norgestimate</th>\n",
              "      <th>Ethinyl estradiol / levonorgestrel</th>\n",
              "      <th>Phentermine</th>\n",
              "      <th>Sertraline</th>\n",
              "      <th>Escitalopram</th>\n",
              "      <th>Mirena</th>\n",
              "      <th>Implanon</th>\n",
              "      <th>Gabapentin</th>\n",
              "      <th>Bupropion</th>\n",
              "      <th>Venlafaxine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>drugName</th>\n",
              "      <td>3657</td>\n",
              "      <td>3336</td>\n",
              "      <td>2850</td>\n",
              "      <td>2156</td>\n",
              "      <td>2117</td>\n",
              "      <td>1888</td>\n",
              "      <td>1543</td>\n",
              "      <td>1360</td>\n",
              "      <td>1292</td>\n",
              "      <td>1242</td>\n",
              "      <td>1102</td>\n",
              "      <td>1047</td>\n",
              "      <td>1022</td>\n",
              "      <td>1016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Levonorgestrel  Etonogestrel  ...  Bupropion  Venlafaxine\n",
              "drugName            3657          3336  ...       1022         1016\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qr1qQ4MuT8Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "75201a9e-d6f7-4458-d4ac-1dc902c36130"
      },
      "source": [
        "pd.DataFrame(data[\"condition\"].value_counts()).head(14).T"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Birth Control</th>\n",
              "      <th>Depression</th>\n",
              "      <th>Pain</th>\n",
              "      <th>Anxiety</th>\n",
              "      <th>Acne</th>\n",
              "      <th>Bipolar Disorde</th>\n",
              "      <th>Insomnia</th>\n",
              "      <th>Weight Loss</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>ADHD</th>\n",
              "      <th>Diabetes, Type 2</th>\n",
              "      <th>Emergency Contraception</th>\n",
              "      <th>High Blood Pressure</th>\n",
              "      <th>Vaginal Yeast Infection</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>28788</td>\n",
              "      <td>9069</td>\n",
              "      <td>6145</td>\n",
              "      <td>5904</td>\n",
              "      <td>5588</td>\n",
              "      <td>4224</td>\n",
              "      <td>3673</td>\n",
              "      <td>3609</td>\n",
              "      <td>3568</td>\n",
              "      <td>3383</td>\n",
              "      <td>2554</td>\n",
              "      <td>2463</td>\n",
              "      <td>2321</td>\n",
              "      <td>2274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Birth Control  ...  Vaginal Yeast Infection\n",
              "condition          28788  ...                     2274\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7MlNc1w_hxR"
      },
      "source": [
        "NUMERO_SAMPLES = 150\n",
        "\n",
        "data = data.drop([\"uniqueID\", \"drugName\", \"condition\", \"date\", \"rating\", \"usefulCount\"], axis = 1).head(NUMERO_SAMPLES) # SACAR ESTOOOOOO!!"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kggrDvz8MFtl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "ac340a45-f146-489d-c228-dd6b5d3c2d61"
      },
      "source": [
        "data[\"clean_review\"] = data[\"review\"].apply(punctuation)\n",
        "data['clean_review'] = data.clean_review.apply(remove_numbers)\n",
        "data['clean_review_lst'] = data.clean_review.apply(to_list)\n",
        "\n",
        "data[\"NonStopwords_review_lst\"] = data.clean_review.apply(remove_stopwords)\n",
        "data[\"NonStopwords_review_str\"] = data.NonStopwords_review_lst.apply(to_string)\n",
        "\n",
        "data[\"NonStopwords_review_lst_MN\"] = data.clean_review.apply(m_negation)\n",
        "data[\"NonStopwords_review_str_MN\"] = data.NonStopwords_review_lst_MN.apply(to_string)\n",
        "\n",
        "data[\"Lemmatized_review_lst\"] = data.NonStopwords_review_lst_MN.apply(lemmatize_review)\n",
        "data[\"Lemmatized_review_str\"] = data.Lemmatized_review_lst.apply(to_string)\n",
        "\n",
        "data[\"Lemmatized_review\"] = data.NonStopwords_review_lst.apply(lemmatize_review)\n",
        "data[\"Lemmatized_review\"] = data.Lemmatized_review.apply(to_string)\n",
        "\n",
        "data[\"words_count\"] = data.Lemmatized_review_lst.apply(count_words)\n",
        "\n",
        "data.head(3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>clean_review</th>\n",
              "      <th>clean_review_lst</th>\n",
              "      <th>NonStopwords_review_lst</th>\n",
              "      <th>NonStopwords_review_str</th>\n",
              "      <th>NonStopwords_review_lst_MN</th>\n",
              "      <th>NonStopwords_review_str_MN</th>\n",
              "      <th>Lemmatized_review_lst</th>\n",
              "      <th>Lemmatized_review_str</th>\n",
              "      <th>Lemmatized_review</th>\n",
              "      <th>words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>it has no side effect i take it in combination...</td>\n",
              "      <td>[it, has, no, side, effect, i, take, it, in, c...</td>\n",
              "      <td>[no, side, effect, take, combination, bystolic...</td>\n",
              "      <td>no side effect take combination bystolic mg fi...</td>\n",
              "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
              "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
              "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
              "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
              "      <td>no side effect take combination bystolic mg fi...</td>\n",
              "      <td>{'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>my son is halfway through his fourth week of i...</td>\n",
              "      <td>[my, son, is, halfway, through, his, fourth, w...</td>\n",
              "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
              "      <td>son halfway fourth week intuniv became concern...</td>\n",
              "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
              "      <td>son halfway fourth week intuniv became concern...</td>\n",
              "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
              "      <td>son halfway fourth week intuniv became concern...</td>\n",
              "      <td>son halfway fourth week intuniv became concern...</td>\n",
              "      <td>{'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>i used to take another oral contraceptive whic...</td>\n",
              "      <td>[i, used, to, take, another, oral, contracepti...</td>\n",
              "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
              "      <td>used take another oral contraceptive pill cycl...</td>\n",
              "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
              "      <td>used take another oral contraceptive pill cycl...</td>\n",
              "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
              "      <td>used take another oral contraceptive pill cycl...</td>\n",
              "      <td>used take another oral contraceptive pill cycl...</td>\n",
              "      <td>{'used': 1, 'take': 1, 'another': 1, 'oral': 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                        words_count\n",
              "0  \"It has no side effect, I take it in combinati...  ...  {'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...\n",
              "1  \"My son is halfway through his fourth week of ...  ...  {'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...\n",
              "2  \"I used to take another oral contraceptive, wh...  ...  {'used': 1, 'take': 1, 'another': 1, 'oral': 1...\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4MsJkEvybZb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "30981809-9cba-4134-e2f0-262acea6f69f"
      },
      "source": [
        "total_count(data[\"words_count\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>day</td>\n",
              "      <td>side_NEG</td>\n",
              "      <td>not_NEG</td>\n",
              "      <td>year</td>\n",
              "      <td>effects_NEG</td>\n",
              "      <td>not</td>\n",
              "      <td>no</td>\n",
              "      <td>started</td>\n",
              "      <td>month</td>\n",
              "      <td>mg</td>\n",
              "      <td>week</td>\n",
              "      <td>taking</td>\n",
              "      <td>time</td>\n",
              "      <td>im</td>\n",
              "      <td>pain</td>\n",
              "      <td>take_NEG</td>\n",
              "      <td>first</td>\n",
              "      <td>ive</td>\n",
              "      <td>get_NEG</td>\n",
              "      <td>like_NEG</td>\n",
              "      <td>would_NEG</td>\n",
              "      <td>im_NEG</td>\n",
              "      <td>no_NEG</td>\n",
              "      <td>doctor</td>\n",
              "      <td>medication</td>\n",
              "      <td>day_NEG</td>\n",
              "      <td>taking_NEG</td>\n",
              "      <td>one</td>\n",
              "      <td>get</td>\n",
              "      <td>take</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41</td>\n",
              "      <td>39</td>\n",
              "      <td>36</td>\n",
              "      <td>34</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "      <td>26</td>\n",
              "      <td>25</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0         1        2     3   ...          26   27   28    29\n",
              "0  day  side_NEG  not_NEG  year  ...  taking_NEG  one  get  take\n",
              "1   41        39       36    34  ...          18   18   17    17\n",
              "\n",
              "[2 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIkt3GDq-vsk"
      },
      "source": [
        "# print(type(data[\"clean_review\"][0]))\n",
        "\n",
        "# print(type(data[\"review_words\"][0]))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs9nl3nHqb1w"
      },
      "source": [
        "# correlation = data[\"rating\"].corr(data[\"usefulCount\"], method='pearson')\n",
        "\n",
        "# correlation"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc1NlfSDsVXo"
      },
      "source": [
        "# plt.matshow(data[[\"rating\", \"usefulCount\"]].corr())\n",
        "# plt.show()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2RL1hUb150D"
      },
      "source": [
        "# Semi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLVyJMxN173f"
      },
      "source": [
        "# seed_topics = {'NASA': 0,\n",
        "#                'SpaceX': 0,\n",
        "#                'Apple': 1,\n",
        "#                'Google': 1,\n",
        "#                'Physics': 2,\n",
        "#                'Chemistry': 2,}model.fit(X, seed_topics=seed_topics, seed_confidence=0.15)."
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLeBPZSEY4Jh"
      },
      "source": [
        "# TF-IDF features | Latent Dirichlet allocation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEIG7yCEv5YH"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df = 0.01, \n",
        "                             max_df = 0.50, \n",
        "                             max_features = None,\n",
        "                             vocabulary = None,\n",
        "                             ngram_range = (1, 2)).fit(manual[\"Lemmatized_review\"]) #\n",
        "\n",
        "# MINDF Ignore terms that have a document frequency strictly higher than the given threshold\n",
        "# MAXDF When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n",
        "\n",
        "data_vectorized = vectorizer.transform(manual[\"Lemmatized_review\"]) #\n",
        "\n",
        "lda_model = LatentDirichletAllocation(n_components = 2,\n",
        "                                      learning_method = 'online',   \n",
        "                                      random_state = 29,\n",
        "                                      #batch_size = 128,\n",
        "                                      learning_decay = 0.5,\n",
        "                                      #learning_offset = 10.0,\n",
        "                                      #evaluate_every = -1,\n",
        "                                      verbose = 0,\n",
        "                                      max_iter = 50).fit(data_vectorized)\n",
        "\n",
        "vocab = vectorizer.get_feature_names()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqhAxWgi3xcx",
        "outputId": "317153ff-7ec6-4e4d-ce7f-883135f1f6be"
      },
      "source": [
        "vectorizer = vectorizer.fit(manual[\"Lemmatized_review\"])\n",
        "tfidf = vectorizer.transform(manual[\"Lemmatized_review\"])\n",
        "vocab = vectorizer.get_feature_names()\n",
        "print(len(vocab))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32zfVtPC37sK"
      },
      "source": [
        "from corextopic import corextopic as ct\n",
        "\n",
        "anchors = []\n",
        "model = ct.Corex(n_hidden = 7, seed=42)\n",
        "model = model.fit(\n",
        "    tfidf,\n",
        "    words = vocab\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGXRTgpD48ZO",
        "outputId": "eb7a4c78-6daa-4284-da18-25e6498aefcc"
      },
      "source": [
        "for i, topic_ngrams in enumerate(model.get_topics(n_words=10)):\n",
        "    topic_ngrams = [ngram[0] for ngram in topic_ngrams if ngram[1] > 0]\n",
        "    print(\"Topic #{}: {}\".format(i+1, \", \".join(topic_ngrams)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1: cat, cost, suboxone, spent, starting, bitten, started using, medical, breast went, went small\n",
            "Topic #2: abilify, caused, caused gain, gain pound, thought, say, overall, cough, get sleep, lady\n",
            "Topic #3: water, irsquom, period, want, sometimes, nexplanon, trulicity, available, drinking\n",
            "Topic #4: vl\n",
            "Topic #5: good response, useful, response, response useful, evening, ringing, itchy, manageable, seemed, lithium\n",
            "Topic #6: birth, birth control, form\n",
            "Topic #7: nuvaring, insomnia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_GDmjgV4Ibw"
      },
      "source": [
        "# Anchors designed to nudge the model towards measuring specific genres\n",
        "anchors = [\n",
        "    [\"headache\", \"side effect\"],\n",
        "    [\"diarrhea\", \"side effect\"],\n",
        "    [\"acne\", \"side effect\"],\n",
        "    [\"problems\", \"side effect\"],\n",
        "    [\"insomnia\", \"side effect\"],\n",
        "    [\"gain pound\", \"caused gain\", \"side effect\"],\n",
        "    [\"good\", \"better\", \"fine\", \"well\", \"no\", \"useful\", \"good\", \"response\", \"no side\"]\n",
        "]\n",
        "anchors = [\n",
        "    [a for a in topic if a in vocab]\n",
        "    for topic in anchors\n",
        "]\n",
        "\n",
        "model = ct.Corex(n_hidden=7, seed=42)\n",
        "model = model.fit(\n",
        "    tfidf,\n",
        "    words=vocab,\n",
        "    anchors=anchors, # Pass the anchors in here\n",
        "    anchor_strength=3 # Tell the model how much it should rely on the anchors\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybmorWVw5jpa",
        "outputId": "6f8bfae8-55f1-4142-a411-00bc983dc7d3"
      },
      "source": [
        "for i, topic_ngrams in enumerate(model.get_topics(n_words=10)):\n",
        "    topic_ngrams = [ngram[0] for ngram in topic_ngrams if ngram[1] > 0]\n",
        "    print(\"Topic #{}: {}\".format(i+1, \", \".join(topic_ngrams)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1: birth control, birth\n",
            "Topic #2: \n",
            "Topic #3: sometimes, wouldnt, zepatier, say, ringing\n",
            "Topic #4: side, vl, side effect\n",
            "Topic #5: cat, nuvaring, needed, evening\n",
            "Topic #6: caused gain, gain pound, period, pound, irsquom\n",
            "Topic #7: response, useful, abilify, response useful, good response, amitiza\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr1ZLpx55m_3"
      },
      "source": [
        "topic_df = pd.DataFrame(\n",
        "    model.transform(tfidf), \n",
        "    columns=[\"topic_{}\".format(i+1) for i in range(7)]).astype(float)\n",
        "\n",
        "topic_df.index = manual.index\n",
        "df = pd.concat([manual, topic_df], axis=1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "MfZ6HVA571RR",
        "outputId": "d2cc3653-5a92-4743-b11a-3d62653c5e6e"
      },
      "source": [
        "df.drop([\"clean_review\", \"clean_review_lst\", \"NonStopwords_review_lst\", \"NonStopwords_review_str\", \"NonStopwords_review_lst_MN\",\n",
        "         \"NonStopwords_review_str_MN\", \"Lemmatized_review_lst\", \"Lemmatized_review_str\", \"words_count\", \"Lemmatized_review\"], axis = 1).head(3)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sideEffect</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>topic_2</th>\n",
              "      <th>topic_3</th>\n",
              "      <th>topic_4</th>\n",
              "      <th>topic_5</th>\n",
              "      <th>topic_6</th>\n",
              "      <th>topic_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"It has no side effect, I take it in combinati...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"My son is halfway through his fourth week of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...  topic_7\n",
              "0  \"It has no side effect, I take it in combinati...  ...      0.0\n",
              "1  \"My son is halfway through his fourth week of ...  ...      1.0\n",
              "2  \"I used to take another oral contraceptive, wh...  ...      0.0\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYN3iIEVNHkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c16917-05a0-4bcd-b2f6-ff01c2a092aa"
      },
      "source": [
        "\"\"\"A model with higher log-likelihood and lower perplexity\n",
        "(exp(-1. * log-likelihood per word)) is considered to be good. Lets check for our model.\"\"\"\n",
        "\n",
        "# Log Likelyhood: Higher the better\n",
        "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
        "\n",
        "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
        "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
        "\n",
        "# See model parameters\n",
        "print(lda_model.get_params())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Likelihood:  -8172.475858222873\n",
            "Perplexity:  17199.05238299002\n",
            "{'batch_size': 128, 'doc_topic_prior': None, 'evaluate_every': -1, 'learning_decay': 0.5, 'learning_method': 'online', 'learning_offset': 10.0, 'max_doc_update_iter': 100, 'max_iter': 50, 'mean_change_tol': 0.001, 'n_components': 2, 'n_jobs': None, 'perp_tol': 0.1, 'random_state': 29, 'topic_word_prior': None, 'total_samples': 1000000.0, 'verbose': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKumHhk_LbDf"
      },
      "source": [
        "# # Define Search Param\n",
        "# search_params = {'n_components' : [2, 3, 4], 'learning_decay' : [.2, .3, .4], \"max_iter\" : [50, 100], \"learning_offset\" : [5, 10]}\n",
        "\n",
        "# # Init the Model\n",
        "# lda = LatentDirichletAllocation()\n",
        "\n",
        "# # Init Grid Search Class\n",
        "# model = GridSearchCV(lda, param_grid=search_params)\n",
        "\n",
        "# # Do the Grid Search\n",
        "# model.fit(data_vectorized)\n",
        "\n",
        "# # Best Model\n",
        "# best_lda_model = model.best_estimator_\n",
        "\n",
        "# # Model Parameters\n",
        "# print(\"Best Model's Params: \", model.best_params_)\n",
        "\n",
        "# # Log Likelihood Score\n",
        "# print(\"Best Log Likelihood Score: \", model.best_score_)\n",
        "\n",
        "# # Perplexity\n",
        "# print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY1zU_sW0FrP"
      },
      "source": [
        "# vectorizer.vocabulary_"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZhVYO5s1iap"
      },
      "source": [
        "# lda_model.components_ # Vectors"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446i6CoQwQ8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4654d635-3d5f-4c97-c786-d12fe2e5e481"
      },
      "source": [
        "print_topics(lda_model, vectorizer)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "[('day', 1.95), ('not', 1.84), ('week', 1.8), ('im', 1.63), ('month', 1.55), ('pain', 1.52), ('side', 1.51), ('no', 1.46), ('side effect', 1.45), ('effect', 1.42)]\n",
            "Topic 1:\n",
            "[('mg', 1.81), ('not', 1.81), ('year', 1.78), ('taking', 1.78), ('work', 1.75), ('pain', 1.73), ('effect', 1.64), ('side', 1.63), ('take', 1.62), ('day', 1.61)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IyvqAG_wZhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16436e38-fcd7-422f-aa75-0185b8c8158b"
      },
      "source": [
        "example = [\"side effect\"]\n",
        "\n",
        "example_vectorized = vectorizer.transform(example)\n",
        "\n",
        "lda_vectors = lda_model.transform(example_vectorized)\n",
        "\n",
        "print(\"topic 0 :\", lda_vectors[0][0])\n",
        "print(\"topic 1 :\", lda_vectors[0][1])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic 0 : 0.35010083056727265\n",
            "topic 1 : 0.6498991694327274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZPGj5Zmvsem",
        "outputId": "208680eb-a82d-475d-8082-60d832ca4865"
      },
      "source": [
        "for review in manual[\"Lemmatized_review_lst\"]:\n",
        "    predictions = []\n",
        "    vectorized = vectorizer.transform(review)\n",
        "    lda_vectors = predictions.append(lda_model.transform(vectorized))\n",
        "\n",
        "predictions"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.59604762, 0.40395238],\n",
              "        [0.65435304, 0.34564696],\n",
              "        [0.35424455, 0.64575545],\n",
              "        [0.51166804, 0.48833196],\n",
              "        [0.45770213, 0.54229787],\n",
              "        [0.35118319, 0.64881681],\n",
              "        [0.39819386, 0.60180614],\n",
              "        [0.34402768, 0.65597232],\n",
              "        [0.32786605, 0.67213395],\n",
              "        [0.35118319, 0.64881681],\n",
              "        [0.34401793, 0.65598207],\n",
              "        [0.34402945, 0.65597055],\n",
              "        [0.34402811, 0.65597189],\n",
              "        [0.28173506, 0.71826494],\n",
              "        [0.65473986, 0.34526014],\n",
              "        [0.34404523, 0.65595477],\n",
              "        [0.30969019, 0.69030981],\n",
              "        [0.39753381, 0.60246619],\n",
              "        [0.30009476, 0.69990524],\n",
              "        [0.30446004, 0.69553996],\n",
              "        [0.563252  , 0.436748  ],\n",
              "        [0.30588105, 0.69411895],\n",
              "        [0.2841019 , 0.7158981 ],\n",
              "        [0.56996919, 0.43003081],\n",
              "        [0.3044677 , 0.6955323 ],\n",
              "        [0.34403005, 0.65596995],\n",
              "        [0.30588105, 0.69411895],\n",
              "        [0.54693097, 0.45306903],\n",
              "        [0.53377802, 0.46622198],\n",
              "        [0.35118319, 0.64881681],\n",
              "        [0.30588105, 0.69411895],\n",
              "        [0.62727852, 0.37272148],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ],\n",
              "        [0.5       , 0.5       ]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDFviiRPQyU1"
      },
      "source": [
        "# # Get Log Likelyhoods from Grid Search Output\n",
        "# n_components = [2, 3, 4]\n",
        "\n",
        "# log_likelyhoods_5 = [round(gscore.mean_validation_score) for gscore in model.cv_results_ if gscore.parameters['learning_decay']==0.2]\n",
        "# log_likelyhoods_7 = [round(gscore.mean_validation_score) for gscore in model.cv_results_ if gscore.parameters['learning_decay']==0.3]\n",
        "# log_likelyhoods_9 = [round(gscore.mean_validation_score) for gscore in model.cv_results_ if gscore.parameters['learning_decay']==0.4]\n",
        "\n",
        "# # Show graph\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# plt.plot(n_components, log_likelyhoods_5, label='0.5')\n",
        "# plt.plot(n_components, log_likelyhoods_7, label='0.7')\n",
        "# plt.plot(n_components, log_likelyhoods_9, label='0.9')\n",
        "\n",
        "# plt.title(\"Choosing Optimal LDA Model\")\n",
        "# plt.xlabel(\"Num Topics\")\n",
        "# plt.ylabel(\"Log Likelyhood Scores\")\n",
        "# plt.legend(title='Learning decay', loc='best')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSydII74ZwOv"
      },
      "source": [
        "# CountVectorizer | Latent Dirichlet allocation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFYlPTjuaz3G"
      },
      "source": [
        "vectorizer = CountVectorizer(min_df = 0.01, \n",
        "                             max_df = 0.50, \n",
        "                             max_features = None,\n",
        "                             vocabulary = None,\n",
        "                             ngram_range = (1, 2)).fit(data[\"Lemmatized_review_str\"])\n",
        "\n",
        "# MINDF Ignore terms that have a document frequency strictly higher than the given threshold\n",
        "# MAXDF When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n",
        "\n",
        "data_vectorized = vectorizer.transform(data[\"Lemmatized_review_str\"])\n",
        "\n",
        "lda_model = LatentDirichletAllocation(n_components = 2,\n",
        "                                      verbose = 0,\n",
        "                                      max_iter = 50).fit(data_vectorized)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFxcGin6OiLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50a74ac-9517-4c13-c4cc-fe0ff13cccc1"
      },
      "source": [
        "\"\"\"A model with higher log-likelihood and lower perplexity\n",
        "(exp(-1. * log-likelihood per word)) is considered to be good. Lets check for our model.\"\"\"\n",
        "\n",
        "# Log Likelyhood: Higher the better\n",
        "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
        "\n",
        "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
        "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
        "\n",
        "# See model parameters\n",
        "print(lda_model.get_params())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Likelihood:  -38127.6917832083\n",
            "Perplexity:  923.3653941434659\n",
            "{'batch_size': 128, 'doc_topic_prior': None, 'evaluate_every': -1, 'learning_decay': 0.7, 'learning_method': 'batch', 'learning_offset': 10.0, 'max_doc_update_iter': 100, 'max_iter': 50, 'mean_change_tol': 0.001, 'n_components': 2, 'n_jobs': None, 'perp_tol': 0.1, 'random_state': None, 'topic_word_prior': None, 'total_samples': 1000000.0, 'verbose': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxSEF9fwOnh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a14d11-333b-4483-8013-fcf8978fe45d"
      },
      "source": [
        "# Define Search Param\n",
        "search_params = {'n_components' : [2, 3, 4], 'learning_decay' : [.2, .3, .4], \"max_iter\" : [50, 100], \"learning_offset\" : [5, 10]}\n",
        "\n",
        "# Init the Model\n",
        "lda = LatentDirichletAllocation()\n",
        "\n",
        "# Init Grid Search Class\n",
        "model = GridSearchCV(lda, param_grid=search_params)\n",
        "\n",
        "# Do the Grid Search\n",
        "model.fit(data_vectorized)\n",
        "\n",
        "# Best Model\n",
        "best_lda_model = model.best_estimator_\n",
        "\n",
        "# Model Parameters\n",
        "print(\"Best Model's Params: \", model.best_params_)\n",
        "\n",
        "# Log Likelihood Score\n",
        "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
        "\n",
        "# Perplexity\n",
        "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Model's Params:  {'learning_decay': 0.4, 'learning_offset': 10, 'max_iter': 100, 'n_components': 2}\n",
            "Best Log Likelihood Score:  -9211.94173617145\n",
            "Model Perplexity:  923.0570433369943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSP_8i87a_t6"
      },
      "source": [
        "# vectorizer.vocabulary_"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35aIxLxia_wv"
      },
      "source": [
        "# lda_model.components_ # Vectors"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHBRCjyhbC_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9fa126-70c1-46b5-ab72-02e52fb5050c"
      },
      "source": [
        "print_topics(lda_model, vectorizer)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0:\n",
            "[('not_neg', 52.4), ('side_neg', 45.34), ('effects_neg', 36.4), ('side_neg effects_neg', 31.43), ('take_neg', 27.46), ('not', 26.75), ('im_neg', 25.45), ('get_neg', 24.47), ('like_neg', 23.42), ('no', 23.35)]\n",
            "Topic 1:\n",
            "[('day', 55.65), ('week', 40.82), ('mg', 31.16), ('pain', 30.75), ('year', 27.6), ('month', 25.28), ('im', 24.5), ('started', 22.33), ('time', 20.88), ('get', 19.3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzIROp9Ccpm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ad502c-bf7a-4d22-a3fe-903df7f4e86d"
      },
      "source": [
        "example = [\"side effect\"]\n",
        "\n",
        "example_vectorized = vectorizer.transform(example)\n",
        "\n",
        "lda_vectors = lda_model.transform(example_vectorized)\n",
        "\n",
        "print(\"topic 0 :\", lda_vectors[0][0])\n",
        "print(\"topic 1 :\", lda_vectors[0][1])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic 0 : 0.12527176489455374\n",
            "topic 1 : 0.8747282351054463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ygXFa-OaOgP"
      },
      "source": [
        "# TF-IDF features | Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu00AB7v5VIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c556e96-194b-485e-c8e2-2dcb89eb786d"
      },
      "source": [
        "import itertools\n",
        "\n",
        "laplace = lidstone = range(1, 4)\n",
        "\n",
        "lap_lid = list(itertools.product(laplace, lidstone))\n",
        "\n",
        "lap_lid"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yBHK5zJXl1u"
      },
      "source": [
        "# # Create Pipeline\n",
        "# pipe = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "#                  ('nb', MultinomialNB())\n",
        "#                 ])\n",
        "\n",
        "# # Set parameters to search (model and vectorizer)\n",
        "# parameters = {\n",
        "#     'tfidf__ngram_range': (lap_lid), # The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted\n",
        "#     'tfidf__min_df': (np.linspace(0.01, 0.49, num = 10)),\n",
        "#     'tfidf__max_df': (np.linspace(0.50, 0.99, num = 10)),\n",
        "#     'nb__alpha': (np.linspace(0.01, 0.99, num = 10)) # Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing)\n",
        "#     }\n",
        "\n",
        "# # Perform grid search\n",
        "# grid_search = GridSearchCV(pipe, parameters,\n",
        "#                            n_jobs=-1, \n",
        "#                            verbose=1,\n",
        "#                            scoring = \"accuracy\", \n",
        "#                            refit=True,\n",
        "#                            cv=5)\n",
        "\n",
        "# grid_search.fit(X, y)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHMCGyAAdqX-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "301db4ee-4c36-4885-8d78-70431f22ea14"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b1068600e498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_search' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tbcRqUkdutT"
      },
      "source": [
        "best_model = grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfbrUsALaap_"
      },
      "source": [
        "# CountVectorizer | Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DM7mA04ywpP"
      },
      "source": [
        "# # Create Pipeline\n",
        "# pipe = Pipeline([('Count', CountVectorizer()),\n",
        "#                  ('nb', MultinomialNB())\n",
        "#                 ])\n",
        "\n",
        "# # Set parameters to search (model and vectorizer)\n",
        "# parameters = {\n",
        "#     'Count__ngram_range': (lap_lid), # The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted\n",
        "#     'Count__min_df': (np.linspace(0.01, 0.49, num = 10)),\n",
        "#     'Count__max_df': (np.linspace(0.50, 0.99, num = 10)),\n",
        "#     'Count__max_features' : ([1 , 2, 3, 4, 5]),\n",
        "#     'nb__alpha': (np.linspace(0.01, 0.99, num = 10)), # Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing)\n",
        "#     }\n",
        "\n",
        "# # Perform grid search\n",
        "# grid_search = GridSearchCV(pipe, parameters, n_jobs=-1, \n",
        "#                            verbose=1, scoring = \"accuracy\", \n",
        "#                            refit=True, cv=5)\n",
        "\n",
        "# grid_search.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xz3WSok5f5F"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yMriaro5gx1"
      },
      "source": [
        "best_model = grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}