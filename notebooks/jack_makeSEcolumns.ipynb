{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - make features/columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import pandas as pd # DataFrame Manipulation Package\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "from sklearn.decomposition import LatentDirichletAllocation # Latent Dirichlet Allocation is a topic model that is used for discovering abstract topics from a collection of documents (variational Bayes algorithm)\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB # The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification)\n",
    "\n",
    "import string # Collection of string operations\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer #Lemmatize using WordNet's built-in morphy function. Returns the input word unchanged if it cannot be found in WordNet.\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from nltk.sentiment.util import mark_negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>45237</td>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Major Depressive Disorde</td>\n",
       "      <td>\"I started Prozac as one of my first anti depr...</td>\n",
       "      <td>2</td>\n",
       "      <td>12-Jan-16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>102810</td>\n",
       "      <td>Aripiprazole</td>\n",
       "      <td>Depression</td>\n",
       "      <td>\"Intake Effexor XR 375 mg, and lorazepam for d...</td>\n",
       "      <td>4</td>\n",
       "      <td>17-Aug-12</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>60280</td>\n",
       "      <td>NuvaRing</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I am torn by the Nuvaring. The convenience is...</td>\n",
       "      <td>5</td>\n",
       "      <td>31-Oct-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10677</td>\n",
       "      <td>Spironolactone</td>\n",
       "      <td>Acne</td>\n",
       "      <td>\"I&amp;#039;m 30 years old.  I started having real...</td>\n",
       "      <td>9</td>\n",
       "      <td>21-Aug-13</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>196244</td>\n",
       "      <td>Fluvoxamine</td>\n",
       "      <td>Anxiety and Stress</td>\n",
       "      <td>\"I&amp;#039;ve suffered from panic attacks and anx...</td>\n",
       "      <td>9</td>\n",
       "      <td>3-Jan-11</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uniqueID        drugName                 condition  \\\n",
       "95     45237      Fluoxetine  Major Depressive Disorde   \n",
       "96    102810    Aripiprazole                Depression   \n",
       "97     60280        NuvaRing             Birth Control   \n",
       "98     10677  Spironolactone                      Acne   \n",
       "99    196244     Fluvoxamine        Anxiety and Stress   \n",
       "\n",
       "                                               review  rating       date  \\\n",
       "95  \"I started Prozac as one of my first anti depr...       2  12-Jan-16   \n",
       "96  \"Intake Effexor XR 375 mg, and lorazepam for d...       4  17-Aug-12   \n",
       "97  \"I am torn by the Nuvaring. The convenience is...       5  31-Oct-11   \n",
       "98  \"I&#039;m 30 years old.  I started having real...       9  21-Aug-13   \n",
       "99  \"I&#039;ve suffered from panic attacks and anx...       9   3-Jan-11   \n",
       "\n",
       "    usefulCount  \n",
       "95           18  \n",
       "96           33  \n",
       "97            0  \n",
       "98           31  \n",
       "99           44  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### read in unlabed data\n",
    "\n",
    "unlabeled_df =  pd.read_csv('/home/jack/code/jackoutthebox/adverse_drug_reactions/raw_data/drugsComTrain_raw.csv', nrows=100)\n",
    "unlabeled_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>sideEffect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>3-Nov-15</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                  drugName                     condition  \\\n",
       "0    206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1     95260                Guanfacine                          ADHD   \n",
       "2     92703                    Lybrel                 Birth Control   \n",
       "3    138000                Ortho Evra                 Birth Control   \n",
       "4     35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "3  \"This is my first time using any form of birth...       8   3-Nov-15   \n",
       "4  \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
       "\n",
       "   usefulCount  sideEffect  \n",
       "0           27         0.0  \n",
       "1          192         1.0  \n",
       "2           17         1.0  \n",
       "3           10         1.0  \n",
       "4           37         1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### read in labeled data from Hendrike\n",
    "\n",
    "labeled_df =  pd.read_csv('/home/jack/code/jackoutthebox/adverse_drug_reactions/raw_data/adr_labelled_data.csv')\n",
    "labeled_df\n",
    "labeled_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import list of side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import list of side effects\n",
    "\n",
    "from csv import reader\n",
    "# read csv file as a list of lists\n",
    "with open('../raw_data/frequent_adr.csv', 'r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    side_effects = list(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_effects.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(side_effects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdominal pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gastrointestinal pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amblyopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anaemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anorexia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "0         Abdominal pain\n",
       "1  Gastrointestinal pain\n",
       "2              Amblyopia\n",
       "3                Anaemia\n",
       "4               Anorexia"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_effect_df = pd.DataFrame(side_effects)\n",
    "side_effect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "si_list = [] \n",
    "for sublist in side_effects: \n",
    "    for item in sublist: si_list.append(item)\n",
    "\n",
    "print(type(si_list))\n",
    "#si_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disorder     92\n",
       "increased    66\n",
       "site         54\n",
       "pain         51\n",
       "infection    40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sideeffects = side_effect_df[0].str.split(expand=True).stack().value_counts()\n",
    "df_sideeffects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions\n",
    "\n",
    "#stop_words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "for negation in [\"no\", \"not\", \"shouldn't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"wasn't\", \"weren't\", \"wouldn't\"]:\n",
    "    stop_words.remove(negation)\n",
    "\n",
    "#stop_words_with side effects\n",
    "\n",
    "stop_words_se = set(stopwords.words('english')) \n",
    "\n",
    "for negation in [\"no\", \"not\", \"shouldn't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"wasn't\", \"weren't\", \"wouldn't\"]:\n",
    "    stop_words_se.remove(negation)\n",
    "\n",
    "for effect in si_list: \n",
    "    stop_words_se.add(effect) \n",
    "    \n",
    "    \n",
    "\n",
    "def to_list(x):\n",
    "    list_words = x.split(' ')\n",
    "    return list_words\n",
    "\n",
    "def to_string(x):\n",
    "    string = \" \".join(x)\n",
    "    return string\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "def punctuation(x):\n",
    "    for punctuation in string.punctuation:\n",
    "        x =  x.replace(punctuation, '')\n",
    "    return x.lower()\n",
    "\n",
    "def remove_numbers (x):\n",
    "    words_only = ''.join([i for i in x if not i.isdigit()])\n",
    "    return words_only\n",
    "\n",
    "def m_negation(x):\n",
    "    tokenized = word_tokenize(x)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    tokenized_neg = mark_negation(without_stopwords)\n",
    "    return tokenized_neg\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    tokenized = word_tokenize(x)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    return without_stopwords\n",
    "\n",
    "def remove_stopwords_se(x):\n",
    "    tokenized = word_tokenize(x)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words_se]\n",
    "    return without_stopwords\n",
    "\n",
    "def m_negation_se(x):\n",
    "    tokenized = word_tokenize(x)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words_se]\n",
    "    tokenized_neg = mark_negation(without_stopwords)\n",
    "    return tokenized_neg\n",
    "\n",
    "def lemmatize_review(x):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    lista = []\n",
    "    for w in x:\n",
    "       lista.append(lemma.lemmatize(w))\n",
    "    return lista\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "def count_words(x):\n",
    "    wordfreq = []\n",
    "    for w in x:\n",
    "        wordfreq.append(x.count(w))\n",
    "    return dict(zip(x, wordfreq))\n",
    "\n",
    "def total_count(x):\n",
    "    total_count = {}\n",
    "    for row in x:\n",
    "        for key in row.keys():\n",
    "          if key in total_count:\n",
    "              total_count[key] += 1\n",
    "          else:\n",
    "              total_count[key] = 1\n",
    "    return pd.DataFrame(sorted(total_count.items(), key=lambda x: x[1], reverse=True)).head(30).T\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], round(topic[i], 2))\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>clean_review_lst</th>\n",
       "      <th>nonStopwords_review_lst</th>\n",
       "      <th>nonStopwords_review_str</th>\n",
       "      <th>nonStopwords_review_lst_MN</th>\n",
       "      <th>nonStopwords_review_str_MN</th>\n",
       "      <th>lemmatized_review_lst</th>\n",
       "      <th>lemmatized_review_str</th>\n",
       "      <th>lemmatized_review</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>it has no side effect i take it in combination...</td>\n",
       "      <td>[it, has, no, side, effect, i, take, it, in, c...</td>\n",
       "      <td>[no, side, effect, take, combination, bystolic...</td>\n",
       "      <td>no side effect take combination bystolic mg fi...</td>\n",
       "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
       "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
       "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
       "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
       "      <td>no side effect take combination bystolic mg fi...</td>\n",
       "      <td>{'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>my son is halfway through his fourth week of i...</td>\n",
       "      <td>[my, son, is, halfway, through, his, fourth, w...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>{'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>i used to take another oral contraceptive whic...</td>\n",
       "      <td>[i, used, to, take, another, oral, contracepti...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>{'used': 1, 'take': 1, 'another': 1, 'oral': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID    drugName                     condition  \\\n",
       "0    206461   Valsartan  Left Ventricular Dysfunction   \n",
       "1     95260  Guanfacine                          ADHD   \n",
       "2     92703      Lybrel                 Birth Control   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "\n",
       "   usefulCount                                       clean_review  \\\n",
       "0           27  it has no side effect i take it in combination...   \n",
       "1          192  my son is halfway through his fourth week of i...   \n",
       "2           17  i used to take another oral contraceptive whic...   \n",
       "\n",
       "                                    clean_review_lst  \\\n",
       "0  [it, has, no, side, effect, i, take, it, in, c...   \n",
       "1  [my, son, is, halfway, through, his, fourth, w...   \n",
       "2  [i, used, to, take, another, oral, contracepti...   \n",
       "\n",
       "                             nonStopwords_review_lst  \\\n",
       "0  [no, side, effect, take, combination, bystolic...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                             nonStopwords_review_str  \\\n",
       "0  no side effect take combination bystolic mg fi...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                          nonStopwords_review_lst_MN  \\\n",
       "0  [no, side_NEG, effect_NEG, take_NEG, combinati...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                          nonStopwords_review_str_MN  \\\n",
       "0  no side_NEG effect_NEG take_NEG combination_NE...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                               lemmatized_review_lst  \\\n",
       "0  [no, side_NEG, effect_NEG, take_NEG, combinati...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                               lemmatized_review_str  \\\n",
       "0  no side_NEG effect_NEG take_NEG combination_NE...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                                   lemmatized_review  \\\n",
       "0  no side effect take combination bystolic mg fi...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                                         words_count  \n",
       "0  {'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...  \n",
       "1  {'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...  \n",
       "2  {'used': 1, 'take': 1, 'another': 1, 'oral': 1...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### enter in juan prepreprocessing - stemming, lemmitization, etc.\n",
    "\n",
    "unlabeled_df[\"clean_review\"] = unlabeled_df[\"review\"].apply(punctuation)\n",
    "unlabeled_df['clean_review'] = unlabeled_df.clean_review.apply(remove_numbers)\n",
    "unlabeled_df['clean_review_lst'] = unlabeled_df.clean_review.apply(to_list)\n",
    "\n",
    "unlabeled_df[\"nonStopwords_review_lst\"] = unlabeled_df.clean_review.apply(remove_stopwords)\n",
    "unlabeled_df[\"nonStopwords_review_str\"] = unlabeled_df.nonStopwords_review_lst.apply(to_string)\n",
    "\n",
    "unlabeled_df[\"nonStopwords_review_lst_MN\"] = unlabeled_df.clean_review.apply(m_negation)\n",
    "unlabeled_df[\"nonStopwords_review_str_MN\"] = unlabeled_df.nonStopwords_review_lst_MN.apply(to_string)\n",
    "\n",
    "unlabeled_df[\"lemmatized_review_lst\"] = unlabeled_df.nonStopwords_review_lst_MN.apply(lemmatize_review)\n",
    "unlabeled_df[\"lemmatized_review_str\"] = unlabeled_df.lemmatized_review_lst.apply(to_string)\n",
    "\n",
    "unlabeled_df[\"lemmatized_review\"] = unlabeled_df.nonStopwords_review_lst.apply(lemmatize_review)\n",
    "unlabeled_df[\"lemmatized_review\"] = unlabeled_df.lemmatized_review.apply(to_string)\n",
    "\n",
    "unlabeled_df[\"words_count\"] = unlabeled_df.lemmatized_review_lst.apply(count_words)\n",
    "\n",
    "unlabeled_df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vectorized dataframe without side effects (include side effects as stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>45237</td>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Major Depressive Disorde</td>\n",
       "      <td>\"I started Prozac as one of my first anti depr...</td>\n",
       "      <td>2</td>\n",
       "      <td>12-Jan-16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>102810</td>\n",
       "      <td>Aripiprazole</td>\n",
       "      <td>Depression</td>\n",
       "      <td>\"Intake Effexor XR 375 mg, and lorazepam for d...</td>\n",
       "      <td>4</td>\n",
       "      <td>17-Aug-12</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>60280</td>\n",
       "      <td>NuvaRing</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I am torn by the Nuvaring. The convenience is...</td>\n",
       "      <td>5</td>\n",
       "      <td>31-Oct-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10677</td>\n",
       "      <td>Spironolactone</td>\n",
       "      <td>Acne</td>\n",
       "      <td>\"I&amp;#039;m 30 years old.  I started having real...</td>\n",
       "      <td>9</td>\n",
       "      <td>21-Aug-13</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>196244</td>\n",
       "      <td>Fluvoxamine</td>\n",
       "      <td>Anxiety and Stress</td>\n",
       "      <td>\"I&amp;#039;ve suffered from panic attacks and anx...</td>\n",
       "      <td>9</td>\n",
       "      <td>3-Jan-11</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uniqueID        drugName                 condition  \\\n",
       "95     45237      Fluoxetine  Major Depressive Disorde   \n",
       "96    102810    Aripiprazole                Depression   \n",
       "97     60280        NuvaRing             Birth Control   \n",
       "98     10677  Spironolactone                      Acne   \n",
       "99    196244     Fluvoxamine        Anxiety and Stress   \n",
       "\n",
       "                                               review  rating       date  \\\n",
       "95  \"I started Prozac as one of my first anti depr...       2  12-Jan-16   \n",
       "96  \"Intake Effexor XR 375 mg, and lorazepam for d...       4  17-Aug-12   \n",
       "97  \"I am torn by the Nuvaring. The convenience is...       5  31-Oct-11   \n",
       "98  \"I&#039;m 30 years old.  I started having real...       9  21-Aug-13   \n",
       "99  \"I&#039;ve suffered from panic attacks and anx...       9   3-Jan-11   \n",
       "\n",
       "    usefulCount  \n",
       "95           18  \n",
       "96           33  \n",
       "97            0  \n",
       "98           31  \n",
       "99           44  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### read in unlabed data\n",
    "\n",
    "unlabeled_no_sideseffects_df =  pd.read_csv('/home/jack/code/jackoutthebox/adverse_drug_reactions/raw_data/drugsComTrain_raw.csv', nrows=100)\n",
    "unlabeled_no_sideseffects_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>clean_review_lst</th>\n",
       "      <th>nonStopwords_review_lst</th>\n",
       "      <th>nonStopwords_review_str</th>\n",
       "      <th>nonStopwords_review_lst_MN</th>\n",
       "      <th>nonStopwords_review_str_MN</th>\n",
       "      <th>lemmatized_review_lst</th>\n",
       "      <th>lemmatized_review_str</th>\n",
       "      <th>lemmatized_review</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>it has no side effect i take it in combination...</td>\n",
       "      <td>[it, has, no, side, effect, i, take, it, in, c...</td>\n",
       "      <td>[no, side, effect, take, combination, bystolic...</td>\n",
       "      <td>no side effect take combination bystolic mg fi...</td>\n",
       "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
       "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
       "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
       "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
       "      <td>no side effect take combination bystolic mg fi...</td>\n",
       "      <td>{'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>my son is halfway through his fourth week of i...</td>\n",
       "      <td>[my, son, is, halfway, through, his, fourth, w...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>{'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>i used to take another oral contraceptive whic...</td>\n",
       "      <td>[i, used, to, take, another, oral, contracepti...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>{'used': 1, 'take': 1, 'another': 1, 'oral': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID    drugName                     condition  \\\n",
       "0    206461   Valsartan  Left Ventricular Dysfunction   \n",
       "1     95260  Guanfacine                          ADHD   \n",
       "2     92703      Lybrel                 Birth Control   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "\n",
       "   usefulCount                                       clean_review  \\\n",
       "0           27  it has no side effect i take it in combination...   \n",
       "1          192  my son is halfway through his fourth week of i...   \n",
       "2           17  i used to take another oral contraceptive whic...   \n",
       "\n",
       "                                    clean_review_lst  \\\n",
       "0  [it, has, no, side, effect, i, take, it, in, c...   \n",
       "1  [my, son, is, halfway, through, his, fourth, w...   \n",
       "2  [i, used, to, take, another, oral, contracepti...   \n",
       "\n",
       "                             nonStopwords_review_lst  \\\n",
       "0  [no, side, effect, take, combination, bystolic...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                             nonStopwords_review_str  \\\n",
       "0  no side effect take combination bystolic mg fi...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                          nonStopwords_review_lst_MN  \\\n",
       "0  [no, side_NEG, effect_NEG, take_NEG, combinati...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                          nonStopwords_review_str_MN  \\\n",
       "0  no side_NEG effect_NEG take_NEG combination_NE...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                               lemmatized_review_lst  \\\n",
       "0  [no, side_NEG, effect_NEG, take_NEG, combinati...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                               lemmatized_review_str  \\\n",
       "0  no side_NEG effect_NEG take_NEG combination_NE...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                                   lemmatized_review  \\\n",
       "0  no side effect take combination bystolic mg fi...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                                         words_count  \n",
       "0  {'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...  \n",
       "1  {'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...  \n",
       "2  {'used': 1, 'take': 1, 'another': 1, 'oral': 1...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_no_sideseffects_df[\"clean_review\"] = unlabeled_no_sideseffects_df[\"review\"].apply(punctuation)\n",
    "unlabeled_no_sideseffects_df['clean_review'] = unlabeled_no_sideseffects_df.clean_review.apply(remove_numbers)\n",
    "unlabeled_no_sideseffects_df['clean_review_lst'] = unlabeled_no_sideseffects_df.clean_review.apply(to_list)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"nonStopwords_review_lst\"] = unlabeled_no_sideseffects_df.clean_review.apply(remove_stopwords_se)\n",
    "unlabeled_no_sideseffects_df[\"nonStopwords_review_str\"] = unlabeled_no_sideseffects_df.nonStopwords_review_lst.apply(to_string)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"nonStopwords_review_lst_MN\"] = unlabeled_no_sideseffects_df.clean_review.apply(m_negation_se)\n",
    "unlabeled_no_sideseffects_df[\"nonStopwords_review_str_MN\"] = unlabeled_no_sideseffects_df.nonStopwords_review_lst_MN.apply(to_string)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"lemmatized_review_lst\"] = unlabeled_no_sideseffects_df.nonStopwords_review_lst_MN.apply(lemmatize_review)\n",
    "unlabeled_no_sideseffects_df[\"lemmatized_review_str\"] = unlabeled_no_sideseffects_df.lemmatized_review_lst.apply(to_string)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"lemmatized_review\"] = unlabeled_no_sideseffects_df.nonStopwords_review_lst.apply(lemmatize_review)\n",
    "unlabeled_no_sideseffects_df[\"lemmatized_review\"] = unlabeled_no_sideseffects_df.lemmatized_review.apply(to_string)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"words_count\"] = unlabeled_no_sideseffects_df.lemmatized_review_lst.apply(count_words)\n",
    "\n",
    "unlabeled_no_sideseffects_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vectorized side effects dataframe - orginal df minus df without side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make columns for whether side effects are mentioned in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-34ffcc5c06c3>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-34ffcc5c06c3>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    df[key] =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### take sides effects from dictionary and create column in dataframe\n",
    "\n",
    "Dummy_side_effects= {\n",
    "    'abdominal': ['constipation', 'diarrhea'],\n",
    "    'skin' : ['rash'],\n",
    "    'vertigo' : ['dizziness', 'drowsiness'],\n",
    "    'headache' : ['headache'],\n",
    "    'mood disorders' : ['insomnia', 'mood swings']}\n",
    "\n",
    "def make_columns(SideEffectdict):\n",
    "    for condition, words in SideEffectdict.items():\n",
    "        #f\"unlabed_df['{key}'] = unlabed_df['clean_review'].str.contains('{value}')\"\n",
    "        for word in words:\n",
    "            contains_key = unlabed_df['clean_review'].str.contains()\n",
    "            df[key] = \n",
    "    return unlabed_df\n",
    "    \n",
    "\n",
    "make_columns(Dummy_side_effects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize words based on lemmitzied reveiws "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize unlabeled df with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(unlabeled_df[\"lemmatized_review\"])\n",
    "\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1544</th>\n",
       "      <th>1545</th>\n",
       "      <th>1546</th>\n",
       "      <th>1547</th>\n",
       "      <th>1548</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1554 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  1544  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     1     0     0     1     0     0  ...     0   \n",
       "\n",
       "   1545  1546  1547  1548  1549  1550  1551  1552  1553  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     1     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1554 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df  = pd.DataFrame(X.toarray())\n",
    "\n",
    "#X_df[0] = X_df[0].apply(vectorizer.get_feature_names())\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 2, ..., 0, 0, 0],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_noSE = vectorizer.fit_transform(unlabeled_no_sideseffects_df[\"review\"])\n",
    "\n",
    "X_noSE.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 1554), (100, 1779))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_noSE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9d578021be42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlista\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcreate_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_merge_SE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-9d578021be42>\u001b[0m in \u001b[0;36mcreate_strings\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlista\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stopwords_se\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d12d5be4349d>\u001b[0m in \u001b[0;36mremove_stopwords_se\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_stopwords_se\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mwithout_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words_se\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwithout_stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \"\"\"\n\u001b[0;32m-> 1272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m         \"\"\"\n\u001b[0;32m-> 1326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m         \"\"\"\n\u001b[0;32m-> 1326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \"\"\"\n\u001b[1;32m   1356\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after_tok\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "list_merge_noSE = ['juan', 'jack', 'peter', 'hendrike']\n",
    "list_merge_SE = ['juan', 'jack', 'peter', 'hendrike', 'headache']\n",
    "\n",
    "def create_strings(x):\n",
    "    lista = []\n",
    "    y = remove_stopwords_se(x)\n",
    "    for i in x:\n",
    "        if i not in y:\n",
    "            lista.append(i)\n",
    "    return lista\n",
    "\n",
    "create_strings(list_merge_SE)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'csr_matrix' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-006e27f07c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_SE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_noSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'csr_matrix' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "X_SE = list(set(X_noSE()) - set(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "inconsistent shapes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a7c73a8d8b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mSE_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_noSE_df\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Another DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_frame\u001b[0;34m(self, other, func, fill_value)\u001b[0m\n\u001b[1;32m   5868\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5870\u001b[0;31m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_to_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_arith_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5871\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mdispatch_to_series\u001b[0;34m(left, right, func, axis)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m#  _frame_arith_method_with_reindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperate_blockwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36moperate_blockwise\u001b[0;34m(self, other, array_op)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mApply\u001b[0m \u001b[0marray_op\u001b[0m \u001b[0mblockwise\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0manother\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moperate_blockwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/internals/ops.py\u001b[0m in \u001b[0;36moperate_blockwise\u001b[0;34m(left, right, array_op)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mlvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_same_shape_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrblk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_ea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_ea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mleft_ea\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mright_ea\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reshape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0muse_numexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inconsistent shapes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: inconsistent shapes"
     ]
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_noSE_df = pd.DataFrame(X_noSE)\n",
    "\n",
    "X_df.head()\n",
    "SE_df = X_noSE_df - X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying to vectorize with TDiF with a custom vocababuly. Not working..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Dummy_side_effects= {\n",
    "    'constipation': 'abdominal',\n",
    "    'diarrhea' : 'abdominal',\n",
    "    'rash' : 'skin',\n",
    "    'dizziness' : 'vertigo',\n",
    "    'drowsiness' : 'vertigo',\n",
    "    'headache' : 'headache',\n",
    "    'insomnia' : 'mood disorders',\n",
    "    'mood swings' : 'mood disorders'}\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 0.01, \n",
    "                             max_df = 0.50, \n",
    "                             max_features = None,\n",
    "                             vocabulary = None,\n",
    "                             ngram_range = (2, 2)).fit(unlabeled_df[\"review\"]) #\n",
    "\n",
    "# MINDF Ignore terms that have a document frequency strictly higher than the given threshold\n",
    "# MAXDF When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n",
    "\n",
    "data_vectorized = vectorizer.transform(unlabeled_df[\"lemmatized_review\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x6534 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1474 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize words based on lemmitzied reveiws - unlabeled without side effects data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dummy_side_effects= {\n",
    "    'constipation': 'abdominal',\n",
    "    'diarrhea' : 'abdominal',\n",
    "    'rash' : 'skin',\n",
    "    'dizziness' : 'vertigo',\n",
    "    'drowsiness' : 'vertigo',\n",
    "    'headache' : 'headache',\n",
    "    'insomnia' : 'mood disorders',\n",
    "    'mood swings' : 'mood disorders'}\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 0.01, \n",
    "                             max_df = 0.50, \n",
    "                             max_features = None,\n",
    "                             vocabulary = None,\n",
    "                             ngram_range = (2, 2)).fit(unlabeled_no_sideseffects_df[\"review\"]) #\n",
    "\n",
    "# MINDF Ignore terms that have a document frequency strictly higher than the given threshold\n",
    "# MAXDF When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n",
    "\n",
    "data_vectorized_se = vectorizer.transform(unlabeled_no_sideseffects_df[\"lemmatized_review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x6534 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1474 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vectorized_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_effects_vectorized = data_vectorized - data_vectorized_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(side_effects_vectorized)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Tim ideas\n",
    "vectorizer = TfidfVectorizer(min_df = 0.01, \n",
    "                             max_df = 0.50, \n",
    "                             max_features = None,\n",
    "                             vocabulary = None,\n",
    "                             ngram_range = (1, 2)).fit(manual[\"Lemmatized_review\"]) #\n",
    "\n",
    "# MINDF Ignore terms that have a document frequency strictly higher than the given threshold\n",
    "# MAXDF When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n",
    "\n",
    "data_vectorized = vectorizer.transform(df_unlabed[\"review\"])\n",
    "\n",
    "make verse dictionary\n",
    "- loop through dict to reverse keys and values 'find all sides effects that could appear and then assign them a categoriy - many to one mapping'\n",
    "\n",
    "loop through keys of reversed dictionary\n",
    "    - for key, what is my index in the vectorized data matrix\n",
    "    - give me the column for that key\n",
    "    - now, all the text that contain 'word'\n",
    "    - make a column in df and give it the name of the word\n",
    "    - use dataframe either add - then can go through previously assinged groupings\n",
    "    \n",
    "**** go thorough text  and remove all text that we don't care about - strip everything that is not a side effect. \n",
    "look at nltk a restrive vocabular - concatenate one big text - words of interest. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
