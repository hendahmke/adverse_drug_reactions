{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - make features/columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import pandas as pd # DataFrame Manipulation Package\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "from sklearn.decomposition import LatentDirichletAllocation # Latent Dirichlet Allocation is a topic model that is used for discovering abstract topics from a collection of documents (variational Bayes algorithm)\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB # The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification)\n",
    "\n",
    "import string # Collection of string operations\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer #Lemmatize using WordNet's built-in morphy function. Returns the input word unchanged if it cannot be found in WordNet.\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from nltk.sentiment.util import mark_negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>45237</td>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Major Depressive Disorde</td>\n",
       "      <td>\"I started Prozac as one of my first anti depr...</td>\n",
       "      <td>2</td>\n",
       "      <td>12-Jan-16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>102810</td>\n",
       "      <td>Aripiprazole</td>\n",
       "      <td>Depression</td>\n",
       "      <td>\"Intake Effexor XR 375 mg, and lorazepam for d...</td>\n",
       "      <td>4</td>\n",
       "      <td>17-Aug-12</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>60280</td>\n",
       "      <td>NuvaRing</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I am torn by the Nuvaring. The convenience is...</td>\n",
       "      <td>5</td>\n",
       "      <td>31-Oct-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10677</td>\n",
       "      <td>Spironolactone</td>\n",
       "      <td>Acne</td>\n",
       "      <td>\"I&amp;#039;m 30 years old.  I started having real...</td>\n",
       "      <td>9</td>\n",
       "      <td>21-Aug-13</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>196244</td>\n",
       "      <td>Fluvoxamine</td>\n",
       "      <td>Anxiety and Stress</td>\n",
       "      <td>\"I&amp;#039;ve suffered from panic attacks and anx...</td>\n",
       "      <td>9</td>\n",
       "      <td>3-Jan-11</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uniqueID        drugName                 condition  \\\n",
       "95     45237      Fluoxetine  Major Depressive Disorde   \n",
       "96    102810    Aripiprazole                Depression   \n",
       "97     60280        NuvaRing             Birth Control   \n",
       "98     10677  Spironolactone                      Acne   \n",
       "99    196244     Fluvoxamine        Anxiety and Stress   \n",
       "\n",
       "                                               review  rating       date  \\\n",
       "95  \"I started Prozac as one of my first anti depr...       2  12-Jan-16   \n",
       "96  \"Intake Effexor XR 375 mg, and lorazepam for d...       4  17-Aug-12   \n",
       "97  \"I am torn by the Nuvaring. The convenience is...       5  31-Oct-11   \n",
       "98  \"I&#039;m 30 years old.  I started having real...       9  21-Aug-13   \n",
       "99  \"I&#039;ve suffered from panic attacks and anx...       9   3-Jan-11   \n",
       "\n",
       "    usefulCount  \n",
       "95           18  \n",
       "96           33  \n",
       "97            0  \n",
       "98           31  \n",
       "99           44  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### read in unlabed data\n",
    "\n",
    "unlabeled_df =  pd.read_csv('/home/jack/code/jackoutthebox/adverse_drug_reactions/raw_data/drugsComTrain_raw.csv', nrows=100)\n",
    "unlabeled_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>sideEffect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>3-Nov-15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                  drugName                     condition  \\\n",
       "0    206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1     95260                Guanfacine                          ADHD   \n",
       "2     92703                    Lybrel                 Birth Control   \n",
       "3    138000                Ortho Evra                 Birth Control   \n",
       "4     35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "3  \"This is my first time using any form of birth...       8   3-Nov-15   \n",
       "4  \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
       "\n",
       "   usefulCount  sideEffect  \n",
       "0           27           0  \n",
       "1          192           1  \n",
       "2           17           1  \n",
       "3           10           1  \n",
       "4           37           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### read in labeled data from Hendrike\n",
    "\n",
    "labeled_df =  pd.read_csv('/home/jack/code/jackoutthebox/adverse_drug_reactions/raw_data/manually_labelled_data.csv')\n",
    "labeled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import list of side effects\n",
    "\n",
    "from csv import reader\n",
    "# read csv file as a list of lists\n",
    "with open('../raw_data/frequent_adr.csv', 'r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    side_effects = list(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_effects.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(side_effects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdominal pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gastrointestinal pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amblyopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anaemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anorexia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "0         Abdominal pain\n",
       "1  Gastrointestinal pain\n",
       "2              Amblyopia\n",
       "3                Anaemia\n",
       "4               Anorexia"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_effect_df = pd.DataFrame(side_effects)\n",
    "side_effect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "si_list = [] \n",
    "for sublist in side_effect: \n",
    "    for item in sublist: si_list.append(item)\n",
    "\n",
    "print(type(si_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Side_Effect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-e8c1245b6ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sideeffects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mside_effect_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSide_Effect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_sideeffects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Side_Effect'"
     ]
    }
   ],
   "source": [
    "df_sideeffects = side_effect_df.Side_Effect.str.split(expand=True).stack().value_counts()\n",
    "df_sideeffects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions\n",
    "\n",
    "#stop_words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "for negation in [\"no\", \"not\", \"shouldn't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"wasn't\", \"weren't\", \"wouldn't\"]:\n",
    "    stop_words.remove(negation)\n",
    "\n",
    "#stop_words_with side effects\n",
    "\n",
    "stop_words_se = set(stopwords.words('english')) \n",
    "\n",
    "for negation in [\"no\", \"not\", \"shouldn't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"wasn't\", \"weren't\", \"wouldn't\"]:\n",
    "    stop_words_se.remove(negation)\n",
    "\n",
    "for effect in si_list: \n",
    "    stop_words_se.add(side_effect) \n",
    "    \n",
    "    \n",
    "\n",
    "def to_list(x):\n",
    "    list_words = x.split(' ')\n",
    "    return list_words\n",
    "\n",
    "def to_string(x):\n",
    "    string = \" \".join(x)\n",
    "    return string\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "def punctuation(x):\n",
    "    for punctuation in string.punctuation:\n",
    "        x =  x.replace(punctuation, '')\n",
    "    return x.lower()\n",
    "\n",
    "def remove_numbers (x):\n",
    "    words_only = ''.join([i for i in x if not i.isdigit()])\n",
    "    return words_only\n",
    "\n",
    "def m_negation(x):\n",
    "    tokenized = word_tokenize(x)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    tokenized_neg = mark_negation(without_stopwords)\n",
    "    return tokenized_neg\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    tokenized = word_tokenize(x)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    return without_stopwords\n",
    "\n",
    "def remove_stopwords_se(x):\n",
    "    tokenized = word_tokenize(x)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words_se]\n",
    "    return without_stopwords\n",
    "\n",
    "def m_negation_se(x):\n",
    "    tokenized = word_tokenize(x)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words_se]\n",
    "    tokenized_neg = mark_negation(without_stopwords)\n",
    "    return tokenized_neg\n",
    "\n",
    "def lemmatize_review(x):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    lista = []\n",
    "    for w in x:\n",
    "       lista.append(lemma.lemmatize(w))\n",
    "    return lista\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "def count_words(x):\n",
    "    wordfreq = []\n",
    "    for w in x:\n",
    "        wordfreq.append(x.count(w))\n",
    "    return dict(zip(x, wordfreq))\n",
    "\n",
    "def total_count(x):\n",
    "    total_count = {}\n",
    "    for row in x:\n",
    "        for key in row.keys():\n",
    "          if key in total_count:\n",
    "              total_count[key] += 1\n",
    "          else:\n",
    "              total_count[key] = 1\n",
    "    return pd.DataFrame(sorted(total_count.items(), key=lambda x: x[1], reverse=True)).head(30).T\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], round(topic[i], 2))\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>clean_review_lst</th>\n",
       "      <th>NonStopwords_review_lst</th>\n",
       "      <th>...</th>\n",
       "      <th>Lemmatized_review_str</th>\n",
       "      <th>Lemmatized_review</th>\n",
       "      <th>words_count</th>\n",
       "      <th>nonStopwords_review_lst</th>\n",
       "      <th>nonStopwords_review_str</th>\n",
       "      <th>nonStopwords_review_lst_MN</th>\n",
       "      <th>nonStopwords_review_str_MN</th>\n",
       "      <th>lemmatized_review_lst</th>\n",
       "      <th>lemmatized_review_str</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "      <td>it has no side effect i take it in combination...</td>\n",
       "      <td>[it, has, no, side, effect, i, take, it, in, c...</td>\n",
       "      <td>[no, side, effect, take, combination, bystolic...</td>\n",
       "      <td>...</td>\n",
       "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
       "      <td>no side effect take combination bystolic mg fi...</td>\n",
       "      <td>{'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...</td>\n",
       "      <td>[no, side, effect, take, combination, bystolic...</td>\n",
       "      <td>no side effect take combination bystolic mg fi...</td>\n",
       "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
       "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
       "      <td>[no, side_NEG, effect_NEG, take_NEG, combinati...</td>\n",
       "      <td>no side_NEG effect_NEG take_NEG combination_NE...</td>\n",
       "      <td>n o   s i d e   e f f e c t   t a k e   c o m ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "      <td>my son is halfway through his fourth week of i...</td>\n",
       "      <td>[my, son, is, halfway, through, his, fourth, w...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>{'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>[son, halfway, fourth, week, intuniv, became, ...</td>\n",
       "      <td>son halfway fourth week intuniv became concern...</td>\n",
       "      <td>s o n   h a l f w a y   f o u r t h   w e e k ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "      <td>i used to take another oral contraceptive whic...</td>\n",
       "      <td>[i, used, to, take, another, oral, contracepti...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>{'used': 1, 'take': 1, 'another': 1, 'oral': 1...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>[used, take, another, oral, contraceptive, pil...</td>\n",
       "      <td>used take another oral contraceptive pill cycl...</td>\n",
       "      <td>u s e d   t a k e   a n o t h e r   o r a l   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID    drugName                     condition  \\\n",
       "0    206461   Valsartan  Left Ventricular Dysfunction   \n",
       "1     95260  Guanfacine                          ADHD   \n",
       "2     92703      Lybrel                 Birth Control   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "\n",
       "   usefulCount                                       clean_review  \\\n",
       "0           27  it has no side effect i take it in combination...   \n",
       "1          192  my son is halfway through his fourth week of i...   \n",
       "2           17  i used to take another oral contraceptive whic...   \n",
       "\n",
       "                                    clean_review_lst  \\\n",
       "0  [it, has, no, side, effect, i, take, it, in, c...   \n",
       "1  [my, son, is, halfway, through, his, fourth, w...   \n",
       "2  [i, used, to, take, another, oral, contracepti...   \n",
       "\n",
       "                             NonStopwords_review_lst  ...  \\\n",
       "0  [no, side, effect, take, combination, bystolic...  ...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...  ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...  ...   \n",
       "\n",
       "                               Lemmatized_review_str  \\\n",
       "0  no side_NEG effect_NEG take_NEG combination_NE...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                                   Lemmatized_review  \\\n",
       "0  no side effect take combination bystolic mg fi...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                                         words_count  \\\n",
       "0  {'no': 1, 'side_NEG': 1, 'effect_NEG': 1, 'tak...   \n",
       "1  {'son': 1, 'halfway': 1, 'fourth': 1, 'week': ...   \n",
       "2  {'used': 1, 'take': 1, 'another': 1, 'oral': 1...   \n",
       "\n",
       "                             nonStopwords_review_lst  \\\n",
       "0  [no, side, effect, take, combination, bystolic...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                             nonStopwords_review_str  \\\n",
       "0  no side effect take combination bystolic mg fi...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                          nonStopwords_review_lst_MN  \\\n",
       "0  [no, side_NEG, effect_NEG, take_NEG, combinati...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                          nonStopwords_review_str_MN  \\\n",
       "0  no side_NEG effect_NEG take_NEG combination_NE...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                               lemmatized_review_lst  \\\n",
       "0  [no, side_NEG, effect_NEG, take_NEG, combinati...   \n",
       "1  [son, halfway, fourth, week, intuniv, became, ...   \n",
       "2  [used, take, another, oral, contraceptive, pil...   \n",
       "\n",
       "                               lemmatized_review_str  \\\n",
       "0  no side_NEG effect_NEG take_NEG combination_NE...   \n",
       "1  son halfway fourth week intuniv became concern...   \n",
       "2  used take another oral contraceptive pill cycl...   \n",
       "\n",
       "                                   lemmatized_review  \n",
       "0  n o   s i d e   e f f e c t   t a k e   c o m ...  \n",
       "1  s o n   h a l f w a y   f o u r t h   w e e k ...  \n",
       "2  u s e d   t a k e   a n o t h e r   o r a l   ...  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### enter in juan prepreprocessing - stemming, lemmitization, etc.\n",
    "\n",
    "unlabeled_df[\"clean_review\"] = unlabeled_df[\"review\"].apply(punctuation)\n",
    "unlabeled_df['clean_review'] = unlabeled_df.clean_review.apply(remove_numbers)\n",
    "unlabeled_df['clean_review_lst'] = unlabeled_df.clean_review.apply(to_list)\n",
    "\n",
    "unlabeled_df[\"nonStopwords_review_lst\"] = unlabeled_df.clean_review.apply(remove_stopwords)\n",
    "unlabeled_df[\"nonStopwords_review_str\"] = unlabeled_df.NonStopwords_review_lst.apply(to_string)\n",
    "\n",
    "unlabeled_df[\"nonStopwords_review_lst_MN\"] = unlabeled_df.clean_review.apply(m_negation)\n",
    "unlabeled_df[\"nonStopwords_review_str_MN\"] = unlabeled_df.NonStopwords_review_lst_MN.apply(to_string)\n",
    "\n",
    "unlabeled_df[\"lemmatized_review_lst\"] = unlabeled_df.NonStopwords_review_lst_MN.apply(lemmatize_review)\n",
    "unlabeled_df[\"lemmatized_review_str\"] = unlabeled_df.Lemmatized_review_lst.apply(to_string)\n",
    "\n",
    "unlabeled_df[\"lemmatized_review\"] = unlabeled_df.NonStopwords_review_lst.apply(lemmatize_review)\n",
    "unlabeled_df[\"lemmatized_review\"] = unlabeled_df.Lemmatized_review.apply(to_string)\n",
    "\n",
    "unlabeled_df[\"words_count\"] = unlabeled_df.Lemmatized_review_lst.apply(count_words)\n",
    "\n",
    "unlabeled_df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vectorized dataframe without side effects (include side effects as stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>45237</td>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Major Depressive Disorde</td>\n",
       "      <td>\"I started Prozac as one of my first anti depr...</td>\n",
       "      <td>2</td>\n",
       "      <td>12-Jan-16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>102810</td>\n",
       "      <td>Aripiprazole</td>\n",
       "      <td>Depression</td>\n",
       "      <td>\"Intake Effexor XR 375 mg, and lorazepam for d...</td>\n",
       "      <td>4</td>\n",
       "      <td>17-Aug-12</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>60280</td>\n",
       "      <td>NuvaRing</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I am torn by the Nuvaring. The convenience is...</td>\n",
       "      <td>5</td>\n",
       "      <td>31-Oct-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10677</td>\n",
       "      <td>Spironolactone</td>\n",
       "      <td>Acne</td>\n",
       "      <td>\"I&amp;#039;m 30 years old.  I started having real...</td>\n",
       "      <td>9</td>\n",
       "      <td>21-Aug-13</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>196244</td>\n",
       "      <td>Fluvoxamine</td>\n",
       "      <td>Anxiety and Stress</td>\n",
       "      <td>\"I&amp;#039;ve suffered from panic attacks and anx...</td>\n",
       "      <td>9</td>\n",
       "      <td>3-Jan-11</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uniqueID        drugName                 condition  \\\n",
       "95     45237      Fluoxetine  Major Depressive Disorde   \n",
       "96    102810    Aripiprazole                Depression   \n",
       "97     60280        NuvaRing             Birth Control   \n",
       "98     10677  Spironolactone                      Acne   \n",
       "99    196244     Fluvoxamine        Anxiety and Stress   \n",
       "\n",
       "                                               review  rating       date  \\\n",
       "95  \"I started Prozac as one of my first anti depr...       2  12-Jan-16   \n",
       "96  \"Intake Effexor XR 375 mg, and lorazepam for d...       4  17-Aug-12   \n",
       "97  \"I am torn by the Nuvaring. The convenience is...       5  31-Oct-11   \n",
       "98  \"I&#039;m 30 years old.  I started having real...       9  21-Aug-13   \n",
       "99  \"I&#039;ve suffered from panic attacks and anx...       9   3-Jan-11   \n",
       "\n",
       "    usefulCount  \n",
       "95           18  \n",
       "96           33  \n",
       "97            0  \n",
       "98           31  \n",
       "99           44  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### read in unlabed data\n",
    "\n",
    "unlabeled_no_sideseffects_df =  pd.read_csv('/home/jack/code/jackoutthebox/adverse_drug_reactions/raw_data/drugsComTrain_raw.csv', nrows=100)\n",
    "unlabeled_no_sideseffects_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'NonStopwords_review_lst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-5bc0643b8e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0munlabeled_no_sideseffects_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nonStopwords_review_lst\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munlabeled_no_sideseffects_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_stopwords_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0munlabeled_no_sideseffects_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nonStopwords_review_str\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munlabeled_no_sideseffects_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNonStopwords_review_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0munlabeled_no_sideseffects_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nonStopwords_review_lst_MN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munlabeled_no_sideseffects_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_negation_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'NonStopwords_review_lst'"
     ]
    }
   ],
   "source": [
    "unlabeled_no_sideseffects_df[\"clean_review\"] = unlabeled_no_sideseffects_df[\"review\"].apply(punctuation)\n",
    "unlabeled_no_sideseffects_df['clean_review'] = unlabeled_no_sideseffects_df.clean_review.apply(remove_numbers)\n",
    "unlabeled_no_sideseffects_df['clean_review_lst'] = unlabeled_no_sideseffects_df.clean_review.apply(to_list)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"nonStopwords_review_lst\"] = unlabeled_no_sideseffects_df.clean_review.apply(remove_stopwords_se)\n",
    "unlabeled_no_sideseffects_df[\"nonStopwords_review_str\"] = unlabeled_no_sideseffects_df.NonStopwords_review_lst.apply(to_string)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"nonStopwords_review_lst_MN\"] = unlabeled_no_sideseffects_df.clean_review.apply(m_negation_se)\n",
    "unlabeled_no_sideseffects_df[\"nonStopwords_review_str_MN\"] = unlabeled_no_sideseffects_df.NonStopwords_review_lst_MN.apply(to_string)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"lemmatized_review_lst\"] = unlabeled_no_sideseffects_df.NonStopwords_review_lst_MN.apply(lemmatize_review)\n",
    "unlabeled_no_sideseffects_df[\"lemmatized_review_str\"] = unlabeled_no_sideseffects_df.Lemmatized_review_lst.apply(to_string)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"lemmatized_review\"] = unlabeled_no_sideseffects_df.NonStopwords_review_lst.apply(lemmatize_review)\n",
    "unlabeled_no_sideseffects_df[\"lemmatized_review\"] = unlabeled_no_sideseffects_df.Lemmatized_review.apply(to_string)\n",
    "\n",
    "unlabeled_no_sideseffects_df[\"words_count\"] = unlabeled_no_sideseffects_df.Lemmatized_review_lst.apply(count_words)\n",
    "\n",
    "unlabeled_no_sideseffects_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vectorized side effects dataframe - orginal df minus df without side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_effects_df = unlabeled_df - unlabeled_no_sideeffects_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make columns for whether side effects are mentioned in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>3-Nov-15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>45298</td>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Hot Flashes</td>\n",
       "      <td>\"I was having hot flashes every night from bei...</td>\n",
       "      <td>10</td>\n",
       "      <td>25-Jan-16</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>190504</td>\n",
       "      <td>Butorphanol</td>\n",
       "      <td>Pain</td>\n",
       "      <td>\"I was initially prescribed this for frequent ...</td>\n",
       "      <td>9</td>\n",
       "      <td>21-Feb-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>183187</td>\n",
       "      <td>Cymbalta</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"I have suffered from anxiety problems my whol...</td>\n",
       "      <td>8</td>\n",
       "      <td>13-Jul-13</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>114593</td>\n",
       "      <td>Codeine / promethazine</td>\n",
       "      <td>Cough</td>\n",
       "      <td>\"This is the only thing will stop my cough. I ...</td>\n",
       "      <td>10</td>\n",
       "      <td>16-Oct-15</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>171920</td>\n",
       "      <td>Amitiza</td>\n",
       "      <td>Irritable Bowel Syndrome</td>\n",
       "      <td>\"I&amp;#039;m a 25 year old woman who has struggle...</td>\n",
       "      <td>8</td>\n",
       "      <td>19-Mar-17</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniqueID                  drugName                     condition  \\\n",
       "0       206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1        95260                Guanfacine                          ADHD   \n",
       "2        92703                    Lybrel                 Birth Control   \n",
       "3       138000                Ortho Evra                 Birth Control   \n",
       "4        35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "...        ...                       ...                           ...   \n",
       "4995     45298                Fluoxetine                   Hot Flashes   \n",
       "4996    190504               Butorphanol                          Pain   \n",
       "4997    183187                  Cymbalta                       Anxiety   \n",
       "4998    114593    Codeine / promethazine                         Cough   \n",
       "4999    171920                   Amitiza      Irritable Bowel Syndrome   \n",
       "\n",
       "                                                 review  rating       date  \\\n",
       "0     \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1     \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2     \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "3     \"This is my first time using any form of birth...       8   3-Nov-15   \n",
       "4     \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
       "...                                                 ...     ...        ...   \n",
       "4995  \"I was having hot flashes every night from bei...      10  25-Jan-16   \n",
       "4996  \"I was initially prescribed this for frequent ...       9  21-Feb-15   \n",
       "4997  \"I have suffered from anxiety problems my whol...       8  13-Jul-13   \n",
       "4998  \"This is the only thing will stop my cough. I ...      10  16-Oct-15   \n",
       "4999  \"I&#039;m a 25 year old woman who has struggle...       8  19-Mar-17   \n",
       "\n",
       "      usefulCount  \n",
       "0              27  \n",
       "1             192  \n",
       "2              17  \n",
       "3              10  \n",
       "4              37  \n",
       "...           ...  \n",
       "4995           26  \n",
       "4996            1  \n",
       "4997           81  \n",
       "4998           21  \n",
       "4999           20  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### take sides effects from dictionary and create column in dataframe\n",
    "\n",
    "Dummy_side_effects= {\n",
    "    'abdominal': ['constipation', 'diarrhea'],\n",
    "    'skin' : ['rash'],\n",
    "    'vertigo' : ['dizziness', 'drowsiness'],\n",
    "    'headache' : ['headache'],\n",
    "    'mood disorders' : ['insomnia', 'mood swings']}\n",
    "\n",
    "def make_columns(SideEffectdict):\n",
    "    for condition, words in SideEffectdict.items():\n",
    "        #f\"unlabed_df['{key}'] = unlabed_df['clean_review'].str.contains('{value}')\"\n",
    "        for word in words:\n",
    "            contains_key = unlabed_df['clean_review'].str.contains()\n",
    "            df[key] = \n",
    "    return unlabed_df\n",
    "    \n",
    "\n",
    "make_columns(Dummy_side_effects)\n",
    "\n",
    "vectorized_df = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Vocabulary of size 5 doesn't contain index 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a710f99aade3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                              \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                              \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummy_side_effects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                              ngram_range = (2, 2)).fit(unlabeled_df[\"review\"]) #\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# MINDF Ignore terms that have a document frequency strictly higher than the given threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m         \u001b[0mmax_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mmin_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/drug_adverse/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_validate_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m                         msg = (\"Vocabulary of size %d doesn't contain index \"\n\u001b[1;32m    453\u001b[0m                                \"%d.\" % (len(vocabulary), i))\n\u001b[0;32m--> 454\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty vocabulary passed to fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Vocabulary of size 5 doesn't contain index 0."
     ]
    }
   ],
   "source": [
    "Dummy_side_effects= {\n",
    "    #'constipation': 'abdominal',\n",
    "    'diarrhea' : 'abdominal',\n",
    "    'rash' : 'skin',\n",
    "    #'dizziness' : 'vertigo',\n",
    "    'drowsiness' : 'vertigo',\n",
    "    'headache' : 'headache',\n",
    "    #'insomnia' : 'mood disorders',\n",
    "    'mood swings' : 'mood disorders'}\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 0.01, \n",
    "                             max_df = 0.50, \n",
    "                             max_features = None,\n",
    "                             vocabulary = Dummy_side_effects,\n",
    "                             ngram_range = (2, 2)).fit(unlabeled_df[\"review\"]) #\n",
    "\n",
    "# MINDF Ignore terms that have a document frequency strictly higher than the given threshold\n",
    "# MAXDF When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n",
    "\n",
    "data_vectorized = vectorizer.transform(unlabeled_df[\"review\"])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Tim ideas\n",
    "vectorizer = TfidfVectorizer(min_df = 0.01, \n",
    "                             max_df = 0.50, \n",
    "                             max_features = None,\n",
    "                             vocabulary = None,\n",
    "                             ngram_range = (1, 2)).fit(manual[\"Lemmatized_review\"]) #\n",
    "\n",
    "# MINDF Ignore terms that have a document frequency strictly higher than the given threshold\n",
    "# MAXDF When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n",
    "\n",
    "data_vectorized = vectorizer.transform(df_unlabed[\"review\"])\n",
    "\n",
    "make verse dictionary\n",
    "- loop through dict to reverse keys and values 'find all sides effects that could appear and then assign them a categoriy - many to one mapping'\n",
    "\n",
    "loop through keys of reversed dictionary\n",
    "    - for key, what is my index in the vectorized data matrix\n",
    "    - give me the column for that key\n",
    "    - now, all the text that contain 'word'\n",
    "    - make a column in df and give it the name of the word\n",
    "    - use dataframe either add - then can go through previously assinged groupings\n",
    "    \n",
    "**** go thorough text  and remove all text that we don't care about - strip everything that is not a side effect. \n",
    "look at nltk a restrive vocabular - concatenate one big text - words of interest. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
